# Chat model
quarkus.langchain4j.ollama.chat-model.model-name=${OLLAMA_MODEL_NAME:qwen3:14b}
quarkus.langchain4j.ollama.chat-model.temperature=1
quarkus.langchain4j.timeout=180s
quarkus.langchain4j.ollama.base-url=http://localhost:11434
ollama.api-key=${API_KEY:dummy}
# Embedding model
quarkus.langchain4j.ollama.embedding-model.model-name=snowflake-arctic-embed:latest
# Vector store
quarkus.langchain4j.pgvector.dimension=1024
# Memory
quarkus.langchain4j.chat-memory.type=MESSAGE_WINDOW
quarkus.langchain4j.chat-memory.memory-window.max-messages=10
#
quarkus.http.root-path=/api/cortex-m/v1